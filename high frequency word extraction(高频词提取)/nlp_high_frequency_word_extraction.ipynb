{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8d7edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7be91f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"研究生命起源\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ae5e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list_1 = jieba.cut(sent,cut_all=True)\n",
    "seg_list_2 = jieba.cut(sent,cut_all=False)\n",
    "seg_list_3 = jieba.cut(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "097821f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全模式 研究/研究生/生命/起源\n"
     ]
    }
   ],
   "source": [
    "print(\"全模式\",'/'.join(seg_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e87349c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精确模式： 研究/生命/起源\n"
     ]
    }
   ],
   "source": [
    "print(\"精确模式：\",'/'.join(seg_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b20b3ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print((seg_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3c25b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_search = jieba.cut_for_search(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "740b64fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "搜索引擎模式： 研究/生命/起源\n"
     ]
    }
   ],
   "source": [
    "print(\"搜索引擎模式：\",'/'.join(seg_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc8a9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取文件内容         PS:感觉内存消耗是不是太大了呢？\n",
    "def get_condent(path):\n",
    "    with open(path,\"r\",encoding=\"utf-8\") as condent_txt:\n",
    "        condent = \"\"\n",
    "        for word in condent_txt:\n",
    "            word = word.strip()     #用来消除空格\n",
    "            condent += word\n",
    "    return condent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c31aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TF(words, topk = 10):\n",
    "    tf_dic = {}\n",
    "    for w in words:\n",
    "        tf_dic[w] = tf_dic.get(w, 0) + 1#赋值语句代码等价于 tf_dic[w]=0 tf_dic[i]=tf_dic[i]+1\n",
    "    return sorted(tf_dic.items(),key = lambda x: x[1],reverse=True)[:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d69b3390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本之一为：一声巨响之下，死亡的气息瞬问弥漫于整个八荒，这死亡的气息，所蕴含的却不是死亡，而是生机，似乎这是充满了无尽生机的死亡这样的说法是充满了矛盾，但是，让任何人去感受这样的死亡气息之时，都会感觉是这是带着磅礴生机的死亡。听到“哗啦”的声音响起，在这个时候，有坟慕被掀开，有死人从坟慕之中爬了出来，也有古战场之中浮现了一个又一个阴魂，这徘徊千百万年的阴魂在这个时候凝成了身躯。“祖宗-_”在八荒之中，有不少大教疆国，秘门传承的祖坟之中，爬出了一个又一个的死人，或者是凝集成了一个又一个的死魂“列祖列宗诈尸了。“看到宗门之内的祖坟之中，爬出了一位又一位的祖宗，这让门下的弟子、老祖都不由为之毛骨悚然。\n",
      "样本分词效果：一声/巨响/之下/，/死亡/的/气息/瞬问/弥漫/于/整个/八荒/，/这/死亡/的/气息/，/所/蕴含/的/却/不是/死亡/，/而是/生机/，/似乎/这是/充满/了/无尽/生机/的/死亡/这样/的/说法/是/充满/了/矛盾/，/但是/，/让/任何人/去/感受/这样/的/死亡/气息/之/时/，/都/会/感觉/是/这/是/带/着/磅礴/生机/的/死亡/。/听到/“/哗啦/”/的/声音/响起/，/在/这个/时候/，/有/坟慕/被/掀开/，/有/死/人/从/坟慕/之中/爬/了/出来/，/也/有/古战场/之中/浮现/了/一个/又/一个/阴魂/，/这/徘徊/千百万年/的/阴魂/在/这个/时候/凝成/了/身躯/。/“/祖宗/-_/”/在/八荒/之中/，/有/不少/大教疆国/，/秘门/传承/的/祖坟/之中/，/爬/出/了/一个/又/一个/的/死/人/，/或者/是/凝集/成/了/一个/又/一个/的/死魂/“/列祖列宗/诈尸/了/。/“/看到/宗门/之内/的/祖坟/之中/，/爬/出/了/一位/又/一位/的/祖宗/，/这/让/门下/的/弟子/、/老祖/都/不由/为/之/毛骨悚然/。\n",
      "样本的topk(10)[('，', 19), ('的', 15), ('了', 9), ('死亡', 6), ('一个', 6), ('之中', 5), ('这', 4), ('是', 4), ('。', 4), ('“', 4)]\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"data_txt.txt\")    #python中读取文件的一个基本函数\n",
    "corpus = [get_condent(x) for x in files]   #读取文件放入数组中,因为这里只有一个文件，所以数组的索引只有0，所以下面一行的sample_inx为0\n",
    "sample_inx = random.randint(0,len(corpus))\n",
    "split_words = list(jieba.cut(corpus[sample_inx]))\n",
    "print(\"样本之一为：\" + corpus[sample_inx])\n",
    "print(\"样本分词效果：\" + \"/\".join(split_words))\n",
    "print(\"样本的topk(10)\" + str(get_TF(split_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9311375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_inx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
